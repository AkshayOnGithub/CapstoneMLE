{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorative data analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we analyze some text resources present in `../resources`.\n",
    "Resources are made of:\n",
    "- *out-of-domain* resources like irrelevant chatter live in folders `../resources/convo` and `../resources/chatterbox` and are made of various small-talks\n",
    "- *in-domain* text resources are sample knowledge bases (for the moment copy-pastes from online FAQs). Those texts are focused to a specific domain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/jlinho/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jlinho/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download of dictionaries\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../resources/chatterbox/politics.yml',\n",
       " '../resources/chatterbox/ai.yml',\n",
       " '../resources/chatterbox/emotion.yml',\n",
       " '../resources/chatterbox/computers.yml',\n",
       " '../resources/chatterbox/botprofile.yml',\n",
       " '../resources/chatterbox/history.yml',\n",
       " '../resources/chatterbox/psychology.yml',\n",
       " '../resources/chatterbox/food.yml',\n",
       " '../resources/chatterbox/literature.yml',\n",
       " '../resources/chatterbox/money.yml',\n",
       " '../resources/chatterbox/trivia.yml',\n",
       " '../resources/chatterbox/gossip.yml',\n",
       " '../resources/chatterbox/humor.yml',\n",
       " '../resources/chatterbox/conversations.yml',\n",
       " '../resources/chatterbox/greetings.yml',\n",
       " '../resources/chatterbox/sports.yml',\n",
       " '../resources/chatterbox/movies.yml',\n",
       " '../resources/chatterbox/science.yml',\n",
       " '../resources/chatterbox/health.yml']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "resources_dir = Path(\"../resources/\") \n",
    "\n",
    "chatterbox_files = [str(p) for p in Path(resources_dir / \"chatterbox\").glob('**/*.yml')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../resources/chatterbox/politics.yml',\n",
       " '../resources/chatterbox/ai.yml',\n",
       " '../resources/chatterbox/emotion.yml',\n",
       " '../resources/chatterbox/computers.yml',\n",
       " '../resources/chatterbox/botprofile.yml',\n",
       " '../resources/chatterbox/history.yml',\n",
       " '../resources/chatterbox/psychology.yml',\n",
       " '../resources/chatterbox/food.yml',\n",
       " '../resources/chatterbox/literature.yml',\n",
       " '../resources/chatterbox/money.yml',\n",
       " '../resources/chatterbox/trivia.yml',\n",
       " '../resources/chatterbox/gossip.yml',\n",
       " '../resources/chatterbox/humor.yml',\n",
       " '../resources/chatterbox/conversations.yml',\n",
       " '../resources/chatterbox/greetings.yml',\n",
       " '../resources/chatterbox/sports.yml',\n",
       " '../resources/chatterbox/movies.yml',\n",
       " '../resources/chatterbox/science.yml',\n",
       " '../resources/chatterbox/health.yml']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatterbox_files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "team-aajk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "65332318e5de1880006d1f4f1e9db35f53791c9b4f96742e49fe642b780434f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
